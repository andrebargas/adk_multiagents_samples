#  Copyright 2025 Google LLC. This software is provided as-is, without warranty
#  or representation for any use or purpose. Your use of it is subject to your
#  agreement with Google.

from google.adk.agents import LlmAgent, SequentialAgent
from google.adk.tools import FunctionTool
from data_explorer_agent.sub_agents.feedback.prompts import request_feedback_instructions


summarize_conversation = LlmAgent(
    name="SummarizeConversationForFeedback",
    instruction=(
        "You are an AI assistant. Your current task is to summarize the preceding conversation. "
        "The summary should be concise and capture the main points discussed or actions resolved. "
        "This summary will be used to ask the user for feedback on the interaction. "
        "Focus on providing just the summary text as your output."
    ),
    output_key="conversation_summary"
)

request_feedback = LlmAgent(
    name="RequestFeedback",
    instruction=request_feedback_instructions,
    output_key="user_feedBack" 
)

process_feedback = LlmAgent(
    name="ProcessUserFeedback",
    instruction=(
        "You are an AI assistant. Your task is to process user feedback and structure it into a JSON format. "
        "The user has provided the following feedback text: '{{ state.user_feedBack }}'. "
        "You also have access to the current invocation ID: '{{ state.invocation_id }}' and user ID: '{{ state.user_id }}'.\n\n"
        "Please generate a JSON object with the following fields:\n"
        "- score: (int or float) If the user's feedback explicitly mentions a numerical score, use that. Otherwise, use a default value of 0. If the feedback implies sentiment but not a specific score, still use 0 unless a score is explicitly stated.\n"
        "- text: (string) Use the user's feedback text: '{{ state.user_feedBack }}'.\n"
        "- invocation_id: (string) Use the provided invocation ID: '{{ state.invocation_id }}'.\n"
        "- log_type: (string) Set this to 'feedback'.\n"
        "- service_name: (string) Set this to 'data-explorer-agent'.\n"
        "- user_id: (string) Use the provided user ID: '{{ state.user_id }}'.\n\n"
        "Your output should be ONLY the JSON object.\n\n"
        "Example of expected JSON output format:\n"
        "{\n"
        "  \"score\": 0,\n"
        "  \"text\": \"This is great!\",\n"
        "  \"invocation_id\": \"some_invocation_id_123\",\n"
        "  \"log_type\": \"feedback\",\n"
        "  \"service_name\": \"data-explorer-agent\",\n"
        "  \"user_id\": \"user_abc_789\"\n"
        "}"
    ),
    output_key="structured_feedback_json" # Stores the LLM's structured feedback JSON
)

feedback_quest_agent = SequentialAgent(
    name="FeedbackQuestWorkflow",
    description=("""""
FeedbackQuestWorkflow: A sequential agent for intelligent user feedback collection.

Purpose:
  Proactively solicits rich, specific, and contextual feedback by personalizing
  the feedback request based on the preceding interaction. It aims to make the
  feedback process more engaging and yield higher quality insights.

Key Stages & State Progression:
  This workflow executes a sequence of three LlmAgents:

  1. `summarize_conversation` (LlmAgent):
     - Purpose: Summarizes the preceding interaction to provide essential context
       for a relevant feedback request.
     - Relies on: Conversation history being available in the initial state
       (e.g., `state['history']`).
     - Produces: `state['conversation_summary']` containing the summary text.

  2. `request_feedback` (LlmAgent):
     - Purpose: Formulates a creative and targeted question for the user,
       focusing on specific 'spotlights' or key points from the summarized
       interaction, to encourage detailed feedback.
     - Relies on: `state['conversation_summary']`.
     - Produces: `state['user_feedBack']`, intended to hold the user's
       actual textual response.
     - **CRITICAL OPERATIONAL ASSUMPTION**: This agent is intentionally
       designed WITHOUT any tools. Its correct operation fundamentally relies
       on the Google ADK framework's intrinsic ability to:
         a) Detect that this LlmAgent's output (the question) is a prompt
            for the user.
         b) Display this LLM-generated question to the user.
         c) Wait for and capture the user's direct textual reply.
         d) Use this captured reply as the effective output of this agent,
            populating `state['user_feedBack']`.
       If the ADK framework does not support this implicit input handling
       for LlmAgents as described, `state['user_feedBack']` will incorrectly
       contain the question generated by the LLM, not the user's answer,
       which would break the intended flow of this workflow. This assumption
       MUST be validated against ADK capabilities.

  3. `process_feedback` (LlmAgent):
     - Purpose: To acknowledge the user's provided feedback gracefully and
       conclude the feedback interaction.
     - Relies on: `state['user_feedBack']` (containing the user's response).
     - Produces: `state['feedback_acknowledgement']` containing a thank you
       message for the user.

Usage:
  `FeedbackQuestWorkflow` is designed to be integrated as a sub-agent within a
  larger root agent. The root agent is responsible for invoking this workflow
  at an appropriate point, providing the necessary initial state (especially
  conversation history), and can then utilize the outputs
  (`conversation_summary`, `user_feedBack`, `feedback_acknowledgement`)
  from the final state returned by this workflow.
"""),
    sub_agents=[summarize_conversation, request_feedback, process_feedback]
)